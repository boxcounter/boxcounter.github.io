<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="Hugo 0.145.0">

  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="author" content="" />
  <meta property="og:url" content="http://boxcounter.com/posts/2024-04-30-issue-langchain-interacts-with-transformers/" />
  <link rel="canonical" href="http://boxcounter.com/posts/2024-04-30-issue-langchain-interacts-with-transformers/" /><link rel="alternate" type="application/atom+xml" href="http://boxcounter.com/index.xml" title="Boxcounter&#39;s blog">

  <script type="application/ld+json">
  {
      "@context" : "http://schema.org",
      "@type" : "BlogPosting",
      "mainEntityOfPage": {
           "@type": "WebPage",
           "@id": "http:\/\/boxcounter.com\/"
      },
      "articleSection" : "posts",
      "name" : "LangChain 和 Transformers 搭配使用出现的续写行为",
      "headline" : "LangChain 和 Transformers 搭配使用出现的续写行为",
      "description" : "简介 最近测试开源大模型的时候，遇到了一个挺隐蔽的 silent error，值得记录一下。\n具体现象是这样：\n几个 Chat 大模型的表现像是在做基础模型的续写，不像是对话。 但他们在 MaaS 或 HuggingFace Space 上的表现却明显是对话。 其中一个模型是阿里开源的 Qwen\/Qwen1.5-14B-Chat。在阿里云的灵积 MaaS 上它的表现很符合预期，就是对话。而我们自己跑起来测试的时候就是续写。\n",
      "inLanguage" : "en-US",
      "author" : "",
      "creator" : "",
      "publisher": "",
      "accountablePerson" : "",
      "copyrightHolder" : "",
      "copyrightYear" : "2024",
      "datePublished": "2024-04-30 00:00:00 \u002b0000 UTC",
      "dateModified" : "2024-04-30 00:00:00 \u002b0000 UTC",
      "url" : "http:\/\/boxcounter.com\/posts\/2024-04-30-issue-langchain-interacts-with-transformers\/",
      "keywords" : [  ]
  }
</script>
<title>LangChain 和 Transformers 搭配使用出现的续写行为</title>
  <meta property="og:title" content="LangChain 和 Transformers 搭配使用出现的续写行为" />
  <meta property="og:type" content="article" />
  <meta property="og:description" content="简介 最近测试开源大模型的时候，遇到了一个挺隐蔽的 silent error，值得记录一下。
具体现象是这样：
几个 Chat 大模型的表现像是在做基础模型的续写，不像是对话。 但他们在 MaaS 或 HuggingFace Space 上的表现却明显是对话。 其中一个模型是阿里开源的 Qwen/Qwen1.5-14B-Chat。在阿里云的灵积 MaaS 上它的表现很符合预期，就是对话。而我们自己跑起来测试的时候就是续写。
" />
  <meta name="description" content="简介 最近测试开源大模型的时候，遇到了一个挺隐蔽的 silent error，值得记录一下。
具体现象是这样：
几个 Chat 大模型的表现像是在做基础模型的续写，不像是对话。 但他们在 MaaS 或 HuggingFace Space 上的表现却明显是对话。 其中一个模型是阿里开源的 Qwen/Qwen1.5-14B-Chat。在阿里云的灵积 MaaS 上它的表现很符合预期，就是对话。而我们自己跑起来测试的时候就是续写。
" />
  <meta property="og:locale" content="zh-cn" /><meta property="og:image" content="" />
  

  
    <style>body{font-family:bree serif,sans-serif;-webkit-font-smoothing:antialiased;margin:0 20px}article{max-width:800px;margin-left:auto;margin-right:auto}a{color:#000;text-decoration:none}a:hover{font-weight:600;text-decoration:underline}.post-ads{margin:50px 0}.markdown-body{font-size:18px;max-width:100%}.markdown-body a{text-decoration:underline;text-decoration-color:#000}.markdown-body blockquote{margin:0;padding:0 1em;color:#57606a;border-left:.25em solid #d0d7de}.markdown-body pre{padding:16px;overflow:auto;border-radius:10px}.markdown-body code{padding:.2em .4em;font-size:85%;background-color:#f6f8fa;border-radius:6px}.markdown-body pre>code{padding:0;font-size:100%;background-color:inherit;border:0}.Chinese .markdown-body{line-height:200%}.site-date-catalog{font-size:2rem}.header-title{font-size:2rem;font-weight:700;margin-top:32px;font-family:bungee shade,sans-serif}.header-title a{text-decoration:none}.header-subtitle{color:#666}.header-items{margin:10px 0}.header-item{margin:0 5px}.header-line{width:100%;border-width:2px;border-color:#482936;border-style:solid none none none}.lang-switch{font-weight:600}#posts-list{min-height:600px}.posts-line{font-size:1.2rem;margin:12px 0}.posts-categories{font-size:.8rem;margin:auto;text-align:center}.posts-category{padding:3px 0;border:#000 2px solid;border-radius:5px}.site-footer{margin-top:50px}.site-footer-item{margin-right:12px}.post-header{margin-bottom:50px}.post-title{font-size:2rem;font-weight:600}.post-tags{display:inline;font-weight:600;padding:2px 5px;margin-right:6px;border:#000 2px solid;border-radius:5px}.post-date{font-weight:800;font-style:italic}.post-author{float:right;font-weight:600}.page-content{min-height:60%}.post-content{margin-bottom:50px}.post-content p{hyphens:auto;line-height:1.8;text-justify:ideographic;margin-bottom:1em}.post-content img{max-width:100%;display:block;margin-right:auto;margin-top:6px}.post-content .post-gallery{display:flex;flex-wrap:wrap;gap:6px}.post-content .post-gallery img{margin-right:auto;margin-top:auto;width:calc(50% - 3px)}.related-content{border-width:3px;border-style:solid;border-color:#000;padding:0 10px;margin-bottom:50px;margin-top:100px}.related-content li{margin:5px 0}.taxonomy-term{font-size:3rem}.gallery-img{text-align:center}.gallery-img span{text-align:center}.gallery-img-desc{font-size:.8em;font-weight:800}#disqus_thread{position:relative}#disqus_thread:after{content:"";display:block;height:55px;width:100%;position:absolute;bottom:0;background:#fff}@media screen and (max-width:600px){.header-title,.header-subtitle,.header-items{}.posts-line{font-size:16px}.markdown-body{font-size:16px}.post-title{font-size:2rem}.post-content p{letter-spacing:.05em}.post-content .post-gallery img{width:100%}}@media screen and (max-width:48em){.posts-category{display:none}}</style>
  
  
    <style>.container,.container-fluid{margin-right:auto;margin-left:auto}.container-fluid{padding-right:2rem;padding-left:2rem}.row{box-sizing:border-box;display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-flex:0;-ms-flex:0 1 auto;flex:initial;-webkit-box-orient:horizontal;-webkit-box-direction:normal;-ms-flex-direction:row;flex-direction:row;-ms-flex-wrap:wrap;flex-wrap:wrap;margin-right:-.5rem;margin-left:-.5rem}.row.reverse{-webkit-box-orient:horizontal;-webkit-box-direction:reverse;-ms-flex-direction:row-reverse;flex-direction:row-reverse}.col.reverse{-webkit-box-orient:vertical;-webkit-box-direction:reverse;-ms-flex-direction:column-reverse;flex-direction:column-reverse}.col-xs,.col-xs-1,.col-xs-10,.col-xs-11,.col-xs-12,.col-xs-2,.col-xs-3,.col-xs-4,.col-xs-5,.col-xs-6,.col-xs-7,.col-xs-8,.col-xs-9,.col-xs-offset-0,.col-xs-offset-1,.col-xs-offset-10,.col-xs-offset-11,.col-xs-offset-12,.col-xs-offset-2,.col-xs-offset-3,.col-xs-offset-4,.col-xs-offset-5,.col-xs-offset-6,.col-xs-offset-7,.col-xs-offset-8,.col-xs-offset-9{box-sizing:border-box;-webkit-box-flex:0;-ms-flex:0 0 auto;flex:none;padding-right:.5rem;padding-left:.5rem}.col-xs{-webkit-box-flex:1;-ms-flex-positive:1;flex-grow:1;-ms-flex-preferred-size:0;flex-basis:0;max-width:100%}.col-xs-1{-ms-flex-preferred-size:8.33333333%;flex-basis:8.33333333%;max-width:8.33333333%}.col-xs-2{-ms-flex-preferred-size:16.66666667%;flex-basis:16.66666667%;max-width:16.66666667%}.col-xs-3{-ms-flex-preferred-size:25%;flex-basis:25%;max-width:25%}.col-xs-4{-ms-flex-preferred-size:33.33333333%;flex-basis:33.33333333%;max-width:33.33333333%}.col-xs-5{-ms-flex-preferred-size:41.66666667%;flex-basis:41.66666667%;max-width:41.66666667%}.col-xs-6{-ms-flex-preferred-size:50%;flex-basis:50%;max-width:50%}.col-xs-7{-ms-flex-preferred-size:58.33333333%;flex-basis:58.33333333%;max-width:58.33333333%}.col-xs-8{-ms-flex-preferred-size:66.66666667%;flex-basis:66.66666667%;max-width:66.66666667%}.col-xs-9{-ms-flex-preferred-size:75%;flex-basis:75%;max-width:75%}.col-xs-10{-ms-flex-preferred-size:83.33333333%;flex-basis:83.33333333%;max-width:83.33333333%}.col-xs-11{-ms-flex-preferred-size:91.66666667%;flex-basis:91.66666667%;max-width:91.66666667%}.col-xs-12{-ms-flex-preferred-size:100%;flex-basis:100%;max-width:100%}.col-xs-offset-0{margin-left:0}.col-xs-offset-1{margin-left:8.33333333%}.col-xs-offset-2{margin-left:16.66666667%}.col-xs-offset-3{margin-left:25%}.col-xs-offset-4{margin-left:33.33333333%}.col-xs-offset-5{margin-left:41.66666667%}.col-xs-offset-6{margin-left:50%}.col-xs-offset-7{margin-left:58.33333333%}.col-xs-offset-8{margin-left:66.66666667%}.col-xs-offset-9{margin-left:75%}.col-xs-offset-10{margin-left:83.33333333%}.col-xs-offset-11{margin-left:91.66666667%}.start-xs{-webkit-box-pack:start;-ms-flex-pack:start;justify-content:flex-start;text-align:start}.center-xs{-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;text-align:center}.end-xs{-webkit-box-pack:end;-ms-flex-pack:end;justify-content:flex-end;text-align:end}.top-xs{-webkit-box-align:start;-ms-flex-align:start;align-items:flex-start}.middle-xs{-webkit-box-align:center;-ms-flex-align:center;align-items:center}.bottom-xs{-webkit-box-align:end;-ms-flex-align:end;align-items:flex-end}.around-xs{-ms-flex-pack:distribute;justify-content:space-around}.between-xs{-webkit-box-pack:justify;-ms-flex-pack:justify;justify-content:space-between}.first-xs{-webkit-box-ordinal-group:0;-ms-flex-order:-1;order:-1}.last-xs{-webkit-box-ordinal-group:2;-ms-flex-order:1;order:1}@media only screen and (min-width:48em){.container{width:49rem}.col-sm,.col-sm-1,.col-sm-10,.col-sm-11,.col-sm-12,.col-sm-2,.col-sm-3,.col-sm-4,.col-sm-5,.col-sm-6,.col-sm-7,.col-sm-8,.col-sm-9,.col-sm-offset-0,.col-sm-offset-1,.col-sm-offset-10,.col-sm-offset-11,.col-sm-offset-12,.col-sm-offset-2,.col-sm-offset-3,.col-sm-offset-4,.col-sm-offset-5,.col-sm-offset-6,.col-sm-offset-7,.col-sm-offset-8,.col-sm-offset-9{box-sizing:border-box;-webkit-box-flex:0;-ms-flex:0 0 auto;flex:none;padding-right:.5rem;padding-left:.5rem}.col-sm{-webkit-box-flex:1;-ms-flex-positive:1;flex-grow:1;-ms-flex-preferred-size:0;flex-basis:0;max-width:100%}.col-sm-1{-ms-flex-preferred-size:8.33333333%;flex-basis:8.33333333%;max-width:8.33333333%}.col-sm-2{-ms-flex-preferred-size:16.66666667%;flex-basis:16.66666667%;max-width:16.66666667%}.col-sm-3{-ms-flex-preferred-size:25%;flex-basis:25%;max-width:25%}.col-sm-4{-ms-flex-preferred-size:33.33333333%;flex-basis:33.33333333%;max-width:33.33333333%}.col-sm-5{-ms-flex-preferred-size:41.66666667%;flex-basis:41.66666667%;max-width:41.66666667%}.col-sm-6{-ms-flex-preferred-size:50%;flex-basis:50%;max-width:50%}.col-sm-7{-ms-flex-preferred-size:58.33333333%;flex-basis:58.33333333%;max-width:58.33333333%}.col-sm-8{-ms-flex-preferred-size:66.66666667%;flex-basis:66.66666667%;max-width:66.66666667%}.col-sm-9{-ms-flex-preferred-size:75%;flex-basis:75%;max-width:75%}.col-sm-10{-ms-flex-preferred-size:83.33333333%;flex-basis:83.33333333%;max-width:83.33333333%}.col-sm-11{-ms-flex-preferred-size:91.66666667%;flex-basis:91.66666667%;max-width:91.66666667%}.col-sm-12{-ms-flex-preferred-size:100%;flex-basis:100%;max-width:100%}.col-sm-offset-0{margin-left:0}.col-sm-offset-1{margin-left:8.33333333%}.col-sm-offset-2{margin-left:16.66666667%}.col-sm-offset-3{margin-left:25%}.col-sm-offset-4{margin-left:33.33333333%}.col-sm-offset-5{margin-left:41.66666667%}.col-sm-offset-6{margin-left:50%}.col-sm-offset-7{margin-left:58.33333333%}.col-sm-offset-8{margin-left:66.66666667%}.col-sm-offset-9{margin-left:75%}.col-sm-offset-10{margin-left:83.33333333%}.col-sm-offset-11{margin-left:91.66666667%}.start-sm{-webkit-box-pack:start;-ms-flex-pack:start;justify-content:flex-start;text-align:start}.center-sm{-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;text-align:center}.end-sm{-webkit-box-pack:end;-ms-flex-pack:end;justify-content:flex-end;text-align:end}.top-sm{-webkit-box-align:start;-ms-flex-align:start;align-items:flex-start}.middle-sm{-webkit-box-align:center;-ms-flex-align:center;align-items:center}.bottom-sm{-webkit-box-align:end;-ms-flex-align:end;align-items:flex-end}.around-sm{-ms-flex-pack:distribute;justify-content:space-around}.between-sm{-webkit-box-pack:justify;-ms-flex-pack:justify;justify-content:space-between}.first-sm{-webkit-box-ordinal-group:0;-ms-flex-order:-1;order:-1}.last-sm{-webkit-box-ordinal-group:2;-ms-flex-order:1;order:1}}@media only screen and (min-width:64em){.container{width:65rem}.col-md,.col-md-1,.col-md-10,.col-md-11,.col-md-12,.col-md-2,.col-md-3,.col-md-4,.col-md-5,.col-md-6,.col-md-7,.col-md-8,.col-md-9,.col-md-offset-0,.col-md-offset-1,.col-md-offset-10,.col-md-offset-11,.col-md-offset-12,.col-md-offset-2,.col-md-offset-3,.col-md-offset-4,.col-md-offset-5,.col-md-offset-6,.col-md-offset-7,.col-md-offset-8,.col-md-offset-9{box-sizing:border-box;-webkit-box-flex:0;-ms-flex:0 0 auto;flex:none;padding-right:.5rem;padding-left:.5rem}.col-md{-webkit-box-flex:1;-ms-flex-positive:1;flex-grow:1;-ms-flex-preferred-size:0;flex-basis:0;max-width:100%}.col-md-1{-ms-flex-preferred-size:8.33333333%;flex-basis:8.33333333%;max-width:8.33333333%}.col-md-2{-ms-flex-preferred-size:16.66666667%;flex-basis:16.66666667%;max-width:16.66666667%}.col-md-3{-ms-flex-preferred-size:25%;flex-basis:25%;max-width:25%}.col-md-4{-ms-flex-preferred-size:33.33333333%;flex-basis:33.33333333%;max-width:33.33333333%}.col-md-5{-ms-flex-preferred-size:41.66666667%;flex-basis:41.66666667%;max-width:41.66666667%}.col-md-6{-ms-flex-preferred-size:50%;flex-basis:50%;max-width:50%}.col-md-7{-ms-flex-preferred-size:58.33333333%;flex-basis:58.33333333%;max-width:58.33333333%}.col-md-8{-ms-flex-preferred-size:66.66666667%;flex-basis:66.66666667%;max-width:66.66666667%}.col-md-9{-ms-flex-preferred-size:75%;flex-basis:75%;max-width:75%}.col-md-10{-ms-flex-preferred-size:83.33333333%;flex-basis:83.33333333%;max-width:83.33333333%}.col-md-11{-ms-flex-preferred-size:91.66666667%;flex-basis:91.66666667%;max-width:91.66666667%}.col-md-12{-ms-flex-preferred-size:100%;flex-basis:100%;max-width:100%}.col-md-offset-0{margin-left:0}.col-md-offset-1{margin-left:8.33333333%}.col-md-offset-2{margin-left:16.66666667%}.col-md-offset-3{margin-left:25%}.col-md-offset-4{margin-left:33.33333333%}.col-md-offset-5{margin-left:41.66666667%}.col-md-offset-6{margin-left:50%}.col-md-offset-7{margin-left:58.33333333%}.col-md-offset-8{margin-left:66.66666667%}.col-md-offset-9{margin-left:75%}.col-md-offset-10{margin-left:83.33333333%}.col-md-offset-11{margin-left:91.66666667%}.start-md{-webkit-box-pack:start;-ms-flex-pack:start;justify-content:flex-start;text-align:start}.center-md{-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;text-align:center}.end-md{-webkit-box-pack:end;-ms-flex-pack:end;justify-content:flex-end;text-align:end}.top-md{-webkit-box-align:start;-ms-flex-align:start;align-items:flex-start}.middle-md{-webkit-box-align:center;-ms-flex-align:center;align-items:center}.bottom-md{-webkit-box-align:end;-ms-flex-align:end;align-items:flex-end}.around-md{-ms-flex-pack:distribute;justify-content:space-around}.between-md{-webkit-box-pack:justify;-ms-flex-pack:justify;justify-content:space-between}.first-md{-webkit-box-ordinal-group:0;-ms-flex-order:-1;order:-1}.last-md{-webkit-box-ordinal-group:2;-ms-flex-order:1;order:1}}@media only screen and (min-width:75em){.container{width:76rem}.col-lg,.col-lg-1,.col-lg-10,.col-lg-11,.col-lg-12,.col-lg-2,.col-lg-3,.col-lg-4,.col-lg-5,.col-lg-6,.col-lg-7,.col-lg-8,.col-lg-9,.col-lg-offset-0,.col-lg-offset-1,.col-lg-offset-10,.col-lg-offset-11,.col-lg-offset-12,.col-lg-offset-2,.col-lg-offset-3,.col-lg-offset-4,.col-lg-offset-5,.col-lg-offset-6,.col-lg-offset-7,.col-lg-offset-8,.col-lg-offset-9{box-sizing:border-box;-webkit-box-flex:0;-ms-flex:0 0 auto;flex:none;padding-right:.5rem;padding-left:.5rem}.col-lg{-webkit-box-flex:1;-ms-flex-positive:1;flex-grow:1;-ms-flex-preferred-size:0;flex-basis:0;max-width:100%}.col-lg-1{-ms-flex-preferred-size:8.33333333%;flex-basis:8.33333333%;max-width:8.33333333%}.col-lg-2{-ms-flex-preferred-size:16.66666667%;flex-basis:16.66666667%;max-width:16.66666667%}.col-lg-3{-ms-flex-preferred-size:25%;flex-basis:25%;max-width:25%}.col-lg-4{-ms-flex-preferred-size:33.33333333%;flex-basis:33.33333333%;max-width:33.33333333%}.col-lg-5{-ms-flex-preferred-size:41.66666667%;flex-basis:41.66666667%;max-width:41.66666667%}.col-lg-6{-ms-flex-preferred-size:50%;flex-basis:50%;max-width:50%}.col-lg-7{-ms-flex-preferred-size:58.33333333%;flex-basis:58.33333333%;max-width:58.33333333%}.col-lg-8{-ms-flex-preferred-size:66.66666667%;flex-basis:66.66666667%;max-width:66.66666667%}.col-lg-9{-ms-flex-preferred-size:75%;flex-basis:75%;max-width:75%}.col-lg-10{-ms-flex-preferred-size:83.33333333%;flex-basis:83.33333333%;max-width:83.33333333%}.col-lg-11{-ms-flex-preferred-size:91.66666667%;flex-basis:91.66666667%;max-width:91.66666667%}.col-lg-12{-ms-flex-preferred-size:100%;flex-basis:100%;max-width:100%}.col-lg-offset-0{margin-left:0}.col-lg-offset-1{margin-left:8.33333333%}.col-lg-offset-2{margin-left:16.66666667%}.col-lg-offset-3{margin-left:25%}.col-lg-offset-4{margin-left:33.33333333%}.col-lg-offset-5{margin-left:41.66666667%}.col-lg-offset-6{margin-left:50%}.col-lg-offset-7{margin-left:58.33333333%}.col-lg-offset-8{margin-left:66.66666667%}.col-lg-offset-9{margin-left:75%}.col-lg-offset-10{margin-left:83.33333333%}.col-lg-offset-11{margin-left:91.66666667%}.start-lg{-webkit-box-pack:start;-ms-flex-pack:start;justify-content:flex-start;text-align:start}.center-lg{-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;text-align:center}.end-lg{-webkit-box-pack:end;-ms-flex-pack:end;justify-content:flex-end;text-align:end}.top-lg{-webkit-box-align:start;-ms-flex-align:start;align-items:flex-start}.middle-lg{-webkit-box-align:center;-ms-flex-align:center;align-items:center}.bottom-lg{-webkit-box-align:end;-ms-flex-align:end;align-items:flex-end}.around-lg{-ms-flex-pack:distribute;justify-content:space-around}.between-lg{-webkit-box-pack:justify;-ms-flex-pack:justify;justify-content:space-between}.first-lg{-webkit-box-ordinal-group:0;-ms-flex-order:-1;order:-1}.last-lg{-webkit-box-ordinal-group:2;-ms-flex-order:1;order:1}}</style>
  

  
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
<script>
  MathJax = {
    tex: {
      displayMath: [['\\[', '\\]'], ['$$', '$$']],  
      inlineMath: [['\\(', '\\)']]                  
    },
    loader:{
      load: ['ui/safe']
    },
  };
</script>


  

  

  <link href="/index.xml" rel="alternate" type="application/rss+xml"
    title="Boxcounter&#39;s blog">
  
  <link rel="preconnect" href="https://fonts.gstatic.com">
  <link href="https://fonts.googleapis.com/css?family=Bree+Serif|Bungee+Shade" rel="stylesheet">
  
  

  
  
</head>


<body>
  <article class="post " id="article">
    <div class="row">
      <div class="col-xs-12">
        <div class="site-header">
          
<header>
  <div class="header-title">
    <a href="/"
      >Boxcounter&#39;s blog</a
    >
  </div>
  <div class="header-subtitle"></div>
</header>
<div class="row end-md header-items">
  
</div>
<div class="row">
   
</div>
<div class="header-line"></div>

        </div>
        <header class="post-header">
          <h1 class="post-title">LangChain 和 Transformers 搭配使用出现的续写行为</h1>
          
          <div class="row post-desc">
            <div class="col-xs-6">
              
              <time class="post-date" datetime="2024-04-30 00:00:00 UTC">
                30 Apr 2024
              </time>
              
            </div>
            <div class="col-xs-6">
              
            </div>
          </div>
          
        </header>

        <div class="post-content markdown-body">
          
          <h2 id="简介">简介</h2>
<p>最近测试开源大模型的时候，遇到了一个挺隐蔽的 silent error，值得记录一下。</p>
<p>具体现象是这样：</p>
<ol>
<li>几个 Chat 大模型的表现像是在做基础模型的续写，不像是对话。</li>
<li>但他们在 MaaS 或 HuggingFace Space 上的表现却明显是对话。</li>
</ol>
<p>其中一个模型是阿里开源的 Qwen/Qwen1.5-14B-Chat。在阿里云的灵积 MaaS 上它的表现很符合预期，就是对话。而我们自己跑起来测试的时候就是续写。</p>
<h2 id="项目">项目</h2>
<p>我们的项目使用了 LangChain v0.1.16 和 Transformers v4.40.1。代码大致是这样：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f0f3f3;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#069;font-weight:bold">from</span> <span style="color:#0cf;font-weight:bold">transformers</span> <span style="color:#069;font-weight:bold">import</span> AutoModelForCausalLM, AutoTokenizer, pipeline
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>tokenizer <span style="color:#555">=</span> AutoTokenizer<span style="color:#555">.</span>from_pretrained(<span style="color:#555">...</span>)
</span></span><span style="display:flex;"><span>model <span style="color:#555">=</span> AutoModelForCausalLM<span style="color:#555">.</span>from_pretrained(<span style="color:#555">...</span>)
</span></span><span style="display:flex;"><span>pipe <span style="color:#555">=</span> pipeline(<span style="color:#c30">&#34;text-generation&#34;</span>, model, tokenizer)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#069;font-weight:bold">from</span> <span style="color:#0cf;font-weight:bold">langchain_core.prompts</span> <span style="color:#069;font-weight:bold">import</span> ChatPromptTemplate
</span></span><span style="display:flex;"><span><span style="color:#069;font-weight:bold">from</span> <span style="color:#0cf;font-weight:bold">langchain_community.llms.huggingface_pipeline</span> <span style="color:#069;font-weight:bold">import</span> HuggingFacePipeline
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>prompt <span style="color:#555">=</span> ChatPromptTemplate<span style="color:#555">.</span>from_messages([
</span></span><span style="display:flex;"><span>    (<span style="color:#c30">&#39;system&#39;</span>, <span style="color:#c30">&#39;You’re a chatbot&#39;</span>),
</span></span><span style="display:flex;"><span>    (<span style="color:#c30">&#39;user&#39;</span>, <span style="color:#c30">&#39;Hey&#39;</span>)
</span></span><span style="display:flex;"><span>])
</span></span><span style="display:flex;"><span>llm <span style="color:#555">=</span> HuggingFacePipeline(pipeline<span style="color:#555">=</span>pipe)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>chain <span style="color:#555">=</span> prompt <span style="color:#555">|</span> llm <span style="color:#555">|</span> <span style="color:#555">...</span>
</span></span></code></pre></div><h2 id="解决">解决</h2>
<p>仔细检查代码和下载的模型，我们并没有发现问题。我的同事国杰参考官方 demo 写了一个测试脚本来执行我们的任务，表现符合预期，是对话。</p>
<p>于是就在我们的项目里自定义了一个<code>CustomPromptTemplate</code>，替换掉 LangChain 的<code>ChatPromptTemplate</code>，大致是：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f0f3f3;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#069;font-weight:bold">from</span> <span style="color:#0cf;font-weight:bold">langchain_core.prompts</span> <span style="color:#069;font-weight:bold">import</span> StringPromptTemplate
</span></span><span style="display:flex;"><span><span style="color:#069;font-weight:bold">from</span> <span style="color:#0cf;font-weight:bold">transformers</span> <span style="color:#069;font-weight:bold">import</span> PreTrainedTokenizer, PreTrainedTokenizerFast
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#069;font-weight:bold">class</span> <span style="color:#0a8;font-weight:bold">CustomPromptTemplate</span>(StringPromptTemplate):
</span></span><span style="display:flex;"><span>    tokenizer: PreTrainedTokenizer <span style="color:#555">|</span> PreTrainedTokenizerFast
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#069;font-weight:bold">def</span> <span style="color:#c0f">format</span>(self, <span style="color:#555">**</span>kwargs):
</span></span><span style="display:flex;"><span>        messages <span style="color:#555">=</span> [
</span></span><span style="display:flex;"><span>            {<span style="color:#c30">&#34;role&#34;</span>: <span style="color:#c30">&#34;system&#34;</span>, <span style="color:#c30">&#34;content&#34;</span>: <span style="color:#c30">&#34;You’re a chatbot&#34;</span>},
</span></span><span style="display:flex;"><span>            {<span style="color:#c30">&#34;role&#34;</span>: <span style="color:#c30">&#34;user&#34;</span>, <span style="color:#c30">&#34;content&#34;</span>: <span style="color:#c30">&#34;Hey&#34;</span>}
</span></span><span style="display:flex;"><span>        ]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#069;font-weight:bold">return</span> self<span style="color:#555">.</span>tokenizer<span style="color:#555">.</span>apply_chat_template(
</span></span><span style="display:flex;"><span>            messages,
</span></span><span style="display:flex;"><span>            tokenize<span style="color:#555">=</span><span style="color:#069;font-weight:bold">False</span>,
</span></span><span style="display:flex;"><span>            add_generation_prompt<span style="color:#555">=</span><span style="color:#069;font-weight:bold">True</span>
</span></span><span style="display:flex;"><span>        )
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>tokenizer <span style="color:#555">=</span> AutoTokenizer<span style="color:#555">.</span>from_pretrained(<span style="color:#555">...</span>)
</span></span><span style="display:flex;"><span><span style="color:#555">...</span>
</span></span><span style="display:flex;"><span>prompt <span style="color:#555">=</span> CustomPromptTemplate(tokenizer)
</span></span><span style="display:flex;"><span>chain <span style="color:#555">=</span> prompt <span style="color:#555">|</span> llm <span style="color:#555">|</span> <span style="color:#555">...</span>
</span></span></code></pre></div><p>再测试，发现我们的项目里开源大模型的输出也是对话了。</p>
<p>到此，问题已经解决了。我对其中的症结产生了兴趣，也想排查是否会引入其他潜在问题。所以顺着解决方案继续分析。</p>
<h2 id="分析">分析</h2>
<p>首先来看 LangChain 和 Transformers 搭配使用时的关键调用链路：</p>
<p><img src="images/Call-Sequence.png" alt="Call Sequence"></p>
<p>关键点是右下角的<code>__call__</code>和<code>preprocess</code>两个方法，来看看 Transformers 的关键代码（完整代码见 <a href="https://github.com/huggingface/Transformers/blob/c712d05aa8fc8ba3ebe465079bd377d2dc9c2e07/src/Transformers/pipelines/text_generation.py#L246">text_generation.py</a>）：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f0f3f3;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#069;font-weight:bold">class</span> <span style="color:#0a8;font-weight:bold">TextGenerationPipeline</span>(Pipeline):
</span></span><span style="display:flex;"><span>    <span style="color:#069;font-weight:bold">def</span> __call__(self, text_inputs, <span style="color:#555">**</span>kwargs):
</span></span><span style="display:flex;"><span>        <span style="color:#069;font-weight:bold">if</span> <span style="color:#366">isinstance</span>(text_inputs, (<span style="color:#366">list</span>, <span style="color:#366">tuple</span>)) <span style="color:#000;font-weight:bold">and</span> <span style="color:#366">isinstance</span>(text_inputs[<span style="color:#f60">0</span>], (<span style="color:#366">list</span>, <span style="color:#366">tuple</span>, <span style="color:#366">dict</span>)):
</span></span><span style="display:flex;"><span>            <span style="color:#09f;font-style:italic"># We have one or more prompts in list-of-dicts format, so this is chat mode</span>
</span></span><span style="display:flex;"><span>            <span style="color:#069;font-weight:bold">if</span> <span style="color:#366">isinstance</span>(text_inputs[<span style="color:#f60">0</span>], <span style="color:#366">dict</span>):
</span></span><span style="display:flex;"><span>                <span style="color:#069;font-weight:bold">return</span> <span style="color:#366">super</span>()<span style="color:#555">.</span>__call__(Chat(text_inputs), <span style="color:#555">**</span>kwargs)
</span></span><span style="display:flex;"><span>            <span style="color:#069;font-weight:bold">else</span>:
</span></span><span style="display:flex;"><span>                chats <span style="color:#555">=</span> [Chat(chat) <span style="color:#069;font-weight:bold">for</span> chat <span style="color:#000;font-weight:bold">in</span> text_inputs]  <span style="color:#09f;font-style:italic"># 🐈 🐈 🐈</span>
</span></span><span style="display:flex;"><span>                <span style="color:#069;font-weight:bold">return</span> <span style="color:#366">super</span>()<span style="color:#555">.</span>__call__(chats, <span style="color:#555">**</span>kwargs)
</span></span><span style="display:flex;"><span>        <span style="color:#069;font-weight:bold">else</span>:
</span></span><span style="display:flex;"><span>            <span style="color:#069;font-weight:bold">return</span> <span style="color:#366">super</span>()<span style="color:#555">.</span>__call__(text_inputs, <span style="color:#555">**</span>kwargs)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#069;font-weight:bold">def</span> <span style="color:#c0f">preprocess</span>(
</span></span><span style="display:flex;"><span>        self,
</span></span><span style="display:flex;"><span>        prompt_text,
</span></span><span style="display:flex;"><span>		<span style="color:#555">...</span>
</span></span><span style="display:flex;"><span>    ):
</span></span><span style="display:flex;"><span>        <span style="color:#069;font-weight:bold">if</span> <span style="color:#366">isinstance</span>(prompt_text, Chat):
</span></span><span style="display:flex;"><span>            inputs <span style="color:#555">=</span> self<span style="color:#555">.</span>tokenizer<span style="color:#555">.</span>apply_chat_template(
</span></span><span style="display:flex;"><span>                prompt_text<span style="color:#555">.</span>messages,
</span></span><span style="display:flex;"><span>				<span style="color:#555">...</span>
</span></span><span style="display:flex;"><span>            )
</span></span><span style="display:flex;"><span>        <span style="color:#069;font-weight:bold">else</span>:
</span></span><span style="display:flex;"><span>            inputs <span style="color:#555">=</span> self<span style="color:#555">.</span>tokenizer(
</span></span><span style="display:flex;"><span>                prefix <span style="color:#555">+</span> prompt_text,
</span></span><span style="display:flex;"><span>                <span style="color:#555">...</span>
</span></span><span style="display:flex;"><span>            )
</span></span><span style="display:flex;"><span>        	<span style="color:#555">...</span>
</span></span></code></pre></div><p>从<code>__call__</code>的代码中可以看出，参数<code>text_inputs</code>必须符合一些类型要求，才会被 Transformers 当作对话处理，后续执行到<code>preprocess</code>方法时才会调用<code>tokenizer.apply_chat_template</code>。</p>
<p>什么类型才符合要求呢？Transformers 最常规的用法就符合，比如：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f0f3f3;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>messages <span style="color:#555">=</span> [
</span></span><span style="display:flex;"><span>    {<span style="color:#c30">&#34;role&#34;</span>: <span style="color:#c30">&#34;system&#34;</span>, <span style="color:#c30">&#34;content&#34;</span>: <span style="color:#c30">&#34;You’re a chatbot&#34;</span>},
</span></span><span style="display:flex;"><span>    {<span style="color:#c30">&#34;role&#34;</span>: <span style="color:#c30">&#34;user&#34;</span>, <span style="color:#c30">&#34;content&#34;</span>: <span style="color:#c30">&#34;Hey&#34;</span>}
</span></span><span style="display:flex;"><span>]
</span></span></code></pre></div><p>它的类型是<code>list[dict]</code>。</p>
<p>而 LangChain 提供的 text_inputs 不符合这些要求，就走到了 else 分支，后续在<code>preprocess</code>方法里没有调用<code>tokenizer.apply_chat_template</code>，被当作非对话处理了。</p>
<p>具体来说是这样，以 LangChain 常见的 prompt template 用法为例：</p>
<pre tabindex="0"><code>prompt = ChatPromptTemplate.from_messages([
    (&#39;system&#39;, &#39;You’re a chatbot&#39;),
    (&#39;user&#39;, &#39;Hey&#39;)
])
</code></pre><p>LangChain 提供给 Transformers 的 text_inputs 是这样的：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f0f3f3;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>[
</span></span><span style="display:flex;"><span>	<span style="color:#c30">&#34;System: </span><span style="color:#c30;font-weight:bold">\n</span><span style="color:#c30">You’re a chatbot</span><span style="color:#c30;font-weight:bold">\n\n</span><span style="color:#c30">Human:Hey&#34;</span>
</span></span><span style="display:flex;"><span>]
</span></span></code></pre></div><p>它的类型是<code>list[str]</code>。</p>
<p>到这里，分析结束。我们有两种解决方案：</p>
<ol>
<li>在调用 Transformers 之前对 prompt 调用<code>tokenizer.apply_chat_template</code>。这也是前述我同事国杰采用的方法。</li>
<li>提供符合 Transformers 需要的 prompt 格式，比如上面提到的<code>list[dict]</code>，由 Transformers 在其内部调用<code>tokenizer.apply_chat_template</code>。</li>
</ol>
<p>如果你对为什么<code>tokenizer.apply_chat_template</code>这么关键感到好奇，可以阅读这两篇文章：</p>
<ol>
<li><a href="https://huggingface.co/docs/transformers/chat_templating">https://huggingface.co/docs/transformers/chat_templating</a></li>
<li><a href="https://huggingface.co/blog/chat-templates">https://huggingface.co/blog/chat-templates</a></li>
</ol>

        </div>

        <div class="row middle-xs">
          <div class="col-xs-12">
            
          </div>
        </div>
        
          <div class="row">
            <div class="col-xs-12">
              
            </div>
          </div>

          



          
          
          <div style="height: 50px;"></div>
          
        

        <div class="site-footer">
  
  
</div>

      </div>
    </div>
  </article>

  
<script>
  
  document.addEventListener("DOMContentLoaded", function() {
    const disqus = document.getElementById('disqus_thread');
    const observer = new MutationObserver(function(mutations) {
      mutations.forEach(function(mutation) {
        const iframes = disqus.getElementsByTagName('iframe');
        if (iframes.length > 1) {
          const commentsIframe = iframes[1];
          while (disqus.firstChild) {
            disqus.removeChild(disqus.firstChild);
          }
          disqus.appendChild(commentsIframe);
          observer.disconnect();
        }
      });
    });
    observer.observe(disqus, { childList: true, subtree: true });
  });
</script>

  

</body>

</html>